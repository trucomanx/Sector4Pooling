{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f294d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "SEED_NUMBER=1;\n",
    "\n",
    "## Kfold \n",
    "K=5;                    # Variable K of kfold\n",
    "FOLD_STATUS_FILE='fold_status.json';\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCHS=200;\n",
    "BATCH_SIZE=32;\n",
    "\n",
    "## Model of network\n",
    "MODEL_TYPE  = 'model_sector4';\n",
    "#MODEL_TYPE = 'model_max'\n",
    "\n",
    "DATASET_NAME = 'mcfer2023';\n",
    "#DATASET_NAME = 'ck+48';\n",
    "\n",
    "CPU_NAME = 'cpulab';\n",
    "\n",
    "OUTPUT_BASE_DIR='output';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c76677-df3b-4ab9-aebd-73ec0245038b",
   "metadata": {},
   "source": [
    "# Bibliotecas externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:11:22.762354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-22 13:11:23.390051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fernando/anaconda3/lib/\n",
      "2023-06-22 13:11:23.390264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fernando/anaconda3/lib/\n",
      "2023-06-22 13:11:23.390268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e27cb9-4b9a-4bec-bd30-d9b7a23ec5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:11:24.246518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:24.250505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:24.250590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e80a0-2ad3-4a43-9a2d-affaa523530a",
   "metadata": {},
   "source": [
    "# Biblioteca local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('library');\n",
    "sys.path.append('../src');\n",
    "\n",
    "import tools_dataset as toolsd\n",
    "import tools_model   as toolsm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5c325-9eda-4f6b-b4d8-99d2d433d896",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32302454-de63-4f6c-be9f-a72aac1643d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MODEL_TYPE: model_sector4\n",
      "         EPOCHS: 200\n",
      "     BATCH_SIZE: 32\n",
      "   DATASET_NAME: mcfer2023\n",
      "       CPU_NAME: cpulab\n",
      "OUTPUT_BASE_DIR: output\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--model':\n",
    "        MODEL_TYPE=sys.argv[n+1];\n",
    "    if sys.argv[n]=='--epochs':\n",
    "        EPOCHS=int(sys.argv[n+1]);\n",
    "    if sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    if sys.argv[n]=='--dataset':\n",
    "        DATASET_NAME=sys.argv[n+1];\n",
    "    if sys.argv[n]=='--cpu':\n",
    "        CPU_NAME=sys.argv[n+1];\n",
    "    if sys.argv[n]=='--output-base-dir':\n",
    "        OUTPUT_BASE_DIR=sys.argv[n+1];\n",
    "        \n",
    "print('     MODEL_TYPE:',MODEL_TYPE)\n",
    "print('         EPOCHS:',EPOCHS)\n",
    "print('     BATCH_SIZE:',BATCH_SIZE)\n",
    "print('   DATASET_NAME:',DATASET_NAME)\n",
    "print('       CPU_NAME:',CPU_NAME)\n",
    "print('OUTPUT_BASE_DIR:',OUTPUT_BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbf13b-1dbe-4a62-bcd2-7347a8c219c5",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f213c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_csv_train_file: /media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/mcfer_v1.0/archive/train/training_labels.csv\n",
      " dataset_csv_test_file: /media/fernando/B0EA304AEA300EDA/Dados/Fernando/DATASET/mcfer_v1.0/archive/test/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_csv_train_file, dataset_csv_test_file, dataset_train_base_dir, input_shape, nout = toolsd.load_dataset(dataset_name=DATASET_NAME,\n",
    "                                                                                                               cpu_name=CPU_NAME);\n",
    "\n",
    "print('dataset_csv_train_file:',dataset_csv_train_file)\n",
    "print(' dataset_csv_test_file:',dataset_csv_test_file)\n",
    "\n",
    "OUTPUT_BASE_DIR=os.path.join(OUTPUT_BASE_DIR,DATASET_NAME);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED_NUMBER)\n",
    "tf.keras.utils.set_random_seed(int(SEED_NUMBER));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation kfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      output_dir: output/mcfer2023/skfold5_model_sector4\n",
      "fold_status_path: output/mcfer2023/skfold5_model_sector4/fold_status.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# output directory\n",
    "output_dir = os.path.join(OUTPUT_BASE_DIR,'skfold'+str(K)+'_'+MODEL_TYPE);\n",
    "\n",
    "# K-fold object\n",
    "kf = StratifiedKFold(n_splits = K, shuffle = True, random_state = SEED_NUMBER);\n",
    "\n",
    "# fold status file\n",
    "fold_status_path=os.path.join(output_dir,FOLD_STATUS_FILE);\n",
    "\n",
    "print('      output_dir:',output_dir)\n",
    "print('fold_status_path:',fold_status_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    filename      label\n",
      "0           angry/angry-contempt/im344_2.png      angry\n",
      "1      disgusted/awful/affectnet_0036766.png  disgusted\n",
      "2       fearful/attention-fearful/im32_1.png    fearful\n",
      "3         happy/attention-happy/im1325_2.png      happy\n",
      "4                neutral/attention/im2_1.png    neutral\n",
      "...                                      ...        ...\n",
      "24215           happy/light-smile/im4742.png      happy\n",
      "24216           happy/light-smile/im4809.png      happy\n",
      "24217         happy/light-smile/im4921_1.png      happy\n",
      "24218           happy/light-smile/im5535.png      happy\n",
      "24219           happy/light-smile/im5545.png      happy\n",
      "\n",
      "[24220 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_data = pd.read_csv(dataset_csv_train_file);\n",
    "print(train_data)\n",
    "\n",
    "# Setting labels\n",
    "Y   = train_data[['label']];\n",
    "\n",
    "L=np.shape(Y)[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [float(0.9), float(1.1)] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757c163-8553-4377-a387-a9cd3131ac04",
   "metadata": {},
   "source": [
    "# Auxiliar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e6ca47-f504-47c5-99ad-db41692d40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: \n",
    "    os.makedirs(output_dir) \n",
    "except: \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 of 5\n",
      "length train: 19376 elements\n",
      "length val  : 4844 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:11:25.147896: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-22 13:11:25.148485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.148594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.148668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.466280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.466395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.466473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-22 13:11:25.466535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9850 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_sector4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 16)      5824      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 4)       5188      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 4)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 16)      5200      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 4)       3140      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 56, 56, 4)        16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 16)        3152      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 4)         1604      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 16)        1616      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 4)         580       \n",
      "                                                                 \n",
      " sector4_pooling2d (Sector4P  (None, 14, 14, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 14, 14, 4)         68        \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 16)        592       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 4)         580       \n",
      "                                                                 \n",
      " sector4_pooling2d_1 (Sector  (None, 7, 7, 16)         0         \n",
      " 4Pooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 7, 7, 4)           68        \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 7, 7, 16)          592       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 7, 7, 4)           580       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 196)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 22)                4334      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,295\n",
      "Trainable params: 33,287\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Found 19376 validated image filenames belonging to 7 classes.\n",
      "Found 4844 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:11:29.265460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-06-22 13:11:29.722328: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-22 13:11:30.793764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-22 13:11:30.795050: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f496c036f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-22 13:11:30.795064: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-06-22 13:11:30.798191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-22 13:11:30.843777: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-22 13:11:30.870378: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - ETA: 0s - loss: 1.7782 - categorical_accuracy: 0.3023\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.29851, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 116s 180ms/step - loss: 1.7782 - categorical_accuracy: 0.3023 - val_loss: 1.8004 - val_categorical_accuracy: 0.2985\n",
      "Epoch 2/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.7049 - categorical_accuracy: 0.3576\n",
      "Epoch 2: val_categorical_accuracy improved from 0.29851 to 0.39017, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 106s 175ms/step - loss: 1.7049 - categorical_accuracy: 0.3576 - val_loss: 1.6525 - val_categorical_accuracy: 0.3902\n",
      "Epoch 3/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.6488 - categorical_accuracy: 0.3950\n",
      "Epoch 3: val_categorical_accuracy improved from 0.39017 to 0.41887, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 107s 177ms/step - loss: 1.6488 - categorical_accuracy: 0.3950 - val_loss: 1.5881 - val_categorical_accuracy: 0.4189\n",
      "Epoch 4/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.6028 - categorical_accuracy: 0.4194\n",
      "Epoch 4: val_categorical_accuracy improved from 0.41887 to 0.43765, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 107s 177ms/step - loss: 1.6028 - categorical_accuracy: 0.4194 - val_loss: 1.5572 - val_categorical_accuracy: 0.4377\n",
      "Epoch 5/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.5675 - categorical_accuracy: 0.4329\n",
      "Epoch 5: val_categorical_accuracy improved from 0.43765 to 0.44922, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 107s 177ms/step - loss: 1.5675 - categorical_accuracy: 0.4329 - val_loss: 1.5215 - val_categorical_accuracy: 0.4492\n",
      "Epoch 6/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.5426 - categorical_accuracy: 0.4453\n",
      "Epoch 6: val_categorical_accuracy improved from 0.44922 to 0.46284, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 106s 175ms/step - loss: 1.5426 - categorical_accuracy: 0.4453 - val_loss: 1.4885 - val_categorical_accuracy: 0.4628\n",
      "Epoch 7/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.5184 - categorical_accuracy: 0.4559\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.46284\n",
      "606/606 [==============================] - 108s 178ms/step - loss: 1.5184 - categorical_accuracy: 0.4559 - val_loss: 1.4984 - val_categorical_accuracy: 0.4505\n",
      "Epoch 8/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.5066 - categorical_accuracy: 0.4579\n",
      "Epoch 8: val_categorical_accuracy improved from 0.46284 to 0.47605, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 106s 175ms/step - loss: 1.5066 - categorical_accuracy: 0.4579 - val_loss: 1.4373 - val_categorical_accuracy: 0.4761\n",
      "Epoch 9/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4808 - categorical_accuracy: 0.4686\n",
      "Epoch 9: val_categorical_accuracy improved from 0.47605 to 0.48927, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 107s 176ms/step - loss: 1.4808 - categorical_accuracy: 0.4686 - val_loss: 1.4132 - val_categorical_accuracy: 0.4893\n",
      "Epoch 10/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4626 - categorical_accuracy: 0.4746\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.48927\n",
      "606/606 [==============================] - 106s 175ms/step - loss: 1.4626 - categorical_accuracy: 0.4746 - val_loss: 1.3921 - val_categorical_accuracy: 0.4893\n",
      "Epoch 11/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4503 - categorical_accuracy: 0.4754\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.48927\n",
      "606/606 [==============================] - 109s 181ms/step - loss: 1.4503 - categorical_accuracy: 0.4754 - val_loss: 1.4182 - val_categorical_accuracy: 0.4779\n",
      "Epoch 12/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4327 - categorical_accuracy: 0.4838\n",
      "Epoch 12: val_categorical_accuracy improved from 0.48927 to 0.49298, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 109s 180ms/step - loss: 1.4327 - categorical_accuracy: 0.4838 - val_loss: 1.3916 - val_categorical_accuracy: 0.4930\n",
      "Epoch 13/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4131 - categorical_accuracy: 0.4893\n",
      "Epoch 13: val_categorical_accuracy improved from 0.49298 to 0.50991, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 108s 178ms/step - loss: 1.4131 - categorical_accuracy: 0.4893 - val_loss: 1.3453 - val_categorical_accuracy: 0.5099\n",
      "Epoch 14/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.4044 - categorical_accuracy: 0.4940\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.50991\n",
      "606/606 [==============================] - 107s 177ms/step - loss: 1.4044 - categorical_accuracy: 0.4940 - val_loss: 1.3518 - val_categorical_accuracy: 0.5039\n",
      "Epoch 15/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.3873 - categorical_accuracy: 0.4953\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.50991\n",
      "606/606 [==============================] - 110s 182ms/step - loss: 1.3873 - categorical_accuracy: 0.4953 - val_loss: 1.3355 - val_categorical_accuracy: 0.5056\n",
      "Epoch 16/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.3743 - categorical_accuracy: 0.5020\n",
      "Epoch 16: val_categorical_accuracy improved from 0.50991 to 0.51321, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 109s 179ms/step - loss: 1.3743 - categorical_accuracy: 0.5020 - val_loss: 1.3388 - val_categorical_accuracy: 0.5132\n",
      "Epoch 17/200\n",
      "606/606 [==============================] - ETA: 0s - loss: 1.3650 - categorical_accuracy: 0.5041\n",
      "Epoch 17: val_categorical_accuracy improved from 0.51321 to 0.51817, saving model to output/mcfer2023/skfold5_model_sector4/model_1.h5\n",
      "606/606 [==============================] - 108s 178ms/step - loss: 1.3650 - categorical_accuracy: 0.5041 - val_loss: 1.3138 - val_categorical_accuracy: 0.5182\n",
      "Epoch 18/200\n",
      "427/606 [====================>.........] - ETA: 30s - loss: 1.3492 - categorical_accuracy: 0.5091"
     ]
    }
   ],
   "source": [
    "import tools_model as mpp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "list_train_index=[];\n",
    "list_val_index=[];\n",
    "for train_index, val_index in kf.split(np.zeros(L),Y):\n",
    "    list_train_index.append(train_index);\n",
    "    list_val_index.append(val_index);\n",
    "\n",
    "import json\n",
    "data_fold =  {'VALIDATION_ACCURACY': [],'VALIDATION_LOSS': [] };\n",
    "\n",
    "fold_var=1;\n",
    "\n",
    "if os.path.isfile(fold_status_path):\n",
    "    # Read JSON file\n",
    "    with open(fold_status_path) as data_file:\n",
    "        data_fold = json.load(data_file)\n",
    "        fold_var=len(data_fold['VALIDATION_ACCURACY'])+1;\n",
    "    \n",
    "while fold_var<=K:\n",
    "    training_data   = train_data.iloc[list_train_index[fold_var-1]]\n",
    "    validation_data = train_data.iloc[list_val_index[fold_var-1]]\n",
    "\n",
    "    print('\\nFold',fold_var,'of',K);\n",
    "    print('length train:',len(list_train_index[fold_var-1]),'elements');\n",
    "    print('length val  :',len(list_val_index[fold_var-1]),'elements');\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    \n",
    "    model, target_size = mpp.create_model(  file_of_weight='',\n",
    "                                            model_type=MODEL_TYPE,\n",
    "                                            input_shape=input_shape,\n",
    "                                            nout=nout)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                                   directory = dataset_train_base_dir,\n",
    "                                                   target_size=target_size,\n",
    "                                                   x_col = \"filename\", \n",
    "                                                   y_col = \"label\",\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   shuffle = True);\n",
    "    \n",
    "    valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_train_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True)\n",
    "    \n",
    "    #STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "    \n",
    "\n",
    "    \n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    # CREATE CALLBACKS\n",
    "    best_model_file=os.path.join(output_dir,get_model_name(fold_var));\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    monitor='val_categorical_accuracy', \n",
    "                                                    save_best_only=True, \n",
    "                                                    verbose=1);\n",
    "    \n",
    "    log_dir = os.path.join(output_dir,\"logs\",\"fit\" , datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    \n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                        #steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                       );\n",
    "    print('***** Saving the history *****')\n",
    "\n",
    "    #PLOT HISTORY\n",
    "    mpp.save_model_history(history,os.path.join(output_dir,\"historical_\"+str(fold_var)+\".csv\"), labels=['categorical_accuracy','loss'],show=False);\n",
    "    \n",
    "    print('***** Loding the best model file ... *****')\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(best_model_file);\n",
    "    \n",
    "    print('***** Evaluating the model ... *****')\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    print(results,\"\\n\\n\");\n",
    "    \n",
    "    data_fold['VALIDATION_ACCURACY'].append(results['categorical_accuracy'])\n",
    "    data_fold['VALIDATION_LOSS'].append(results['loss'])\n",
    "    \n",
    "    # Data fold\n",
    "    with open(fold_status_path, 'w') as f:\n",
    "        json.dump(data_fold, f);\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath=os.path.join(output_dir,\"final_stats.csv\");\n",
    "mean_val_acc=mpp.save_model_stat_kfold(data_fold, fpath);\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.txt'));\n",
    "\n",
    "print(mean_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70e376-46ee-40aa-bd19-1ea149d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fecf1b-cef9-463b-b76d-ff614de2be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
